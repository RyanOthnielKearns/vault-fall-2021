#CS #CS224W #lecture-notes
# Logistics
- discussion threads on Ed for livestreamed lectures, if you want to ask live questions
- Colab 0 recitations available on Canvas Zoom recordings
	- does not need to be handed in

# Agenda
- the "choice of graph representation"
- agree on terminology

# Terminology
- **objects**: nodes, verticies $N$
- **interactions**: links, edges $E$
- **system**: network, graph $G(N, E)$
- **undirected graphs**: symmetrical, reciprocal links
- **directed graphs**: directed links
- **Heterogeneous graph**: $G = (V, E, R, T)$
	- nodes with node types $v_i\in V$
	- edges with relation types $(v_i,r,v_j)\in E$
	- node type $T(v_i)$
	- relation type $r\in R$
	- multiple types of entities connected w/ different types of relations
		- ex. people, content, communities in a social network graph
		- ex. knowledge graphs
- **Node degree $k_i$**: number of edges adjacent to node $i$
	- directed networks have *in-degrees* and *out-degrees*
- **Bipartite graph**: graph w/ nodes dividing into disjoint sets $U$ and $V$ s.t. every link connects something from $U$ to $V$
	- two sets of nodes where links go from one side to the other
	- ex. recommender systems
	- also generalizes to *multipartite graphs*
- **Adjacency matrix**
	- $A_{ij}=1$ if there is a link from node $i$ to node $j$
	- $A_{ij}=0$ if there is not a link from node $i$ to node $j$
	- symmetric when graph is undirected
	- real ones are "empty" -- graphs are super sparse objects in practice ($E << E_{max}$; equivalently $k << N-1$)
- Node & Edge attributes
	- **weight**
	- **ranking**
	- **type**
	- **sign** (+/-)
- **unweighted graphs**: adjacency matrix is 0-1
- **weighted graphs**: adjacency matrix stores non-binary number
- **multigraph**: allows for multiple interactions between given pair of nodes (multiple edges)
- **connectivity**: (for undirected graphs) any two verticies can be joined by a path
	- disconnected graphs made up of one or more **connected components**
# Choosing the proper representation
- how to capture the underlying domain / phenomena?
	- way you assign links determines nature of questions / model you can study / develop
- **Edge list**: just enumerate list of edges
	- Cannot represent isolated nodes
- **Adjacency list**: for each node, have vector of nodes that it's adjacent to

# Traditional Methods for Machine Learning in Graphs
- 3 types of prediction tasks
	- node level
	- link level
	- graph level
- traditional practice: design features for nodes/links/graphs -> train ML model & predict incomplete (test) features
- **using effective features over graphs is key to good model performance**
	- *goal*: make predictions for a set of objects
	- features: $d$-dimensional vectors

## Node-Level Prediction
### Goal
Given $G=(V,E)$
Learn a function $f:V\rightarrow\mathbb{R}$

### Tasks
- node classification
	- goal: characterize structure / position of node in the network (**node features**)
		- degree
			- $k_v$ (counts neighbors)
		- centrality $c_v$
			- take into account node importance -- *how important / central is this node?*
			- **eigenvector centrality**
				- a node is important if surrounded by important neighbors
				- centrality = sum of centrality of neighboring nodes
				- $c_v = (1/\lambda)\sum_{u\in N(v)}c_u$
				- defined recursively -- solved in matrix form
				- $c_v = (1/\lambda)\sum_{u\in N(v)}c_u\longleftrightarrow \lambda c = Ac$
					- centrality $c$ is the eigenvector of $A$
					- largest eigenvalue $\lambda_{max}$ guaranteed to be unique and positive
					- eigenvector $c_{max}$ corresponding to $\lambda_{max}$ is used for centrality
			- **betweenness centrality**: a node is important if it lies on many shortest paths between other nodes
				- lots of nodes have to "go through" you ("gatekeeper")
			- **closeness centrality**: node is important if it has small shortest paths to all other nodes
		- clustering coefficient
			- "how well do your friends know each other?"
			- $e_v =$ #(edges among neighboring nodes) $/ k_v$ choose 2
			- "counts triangles" --> for your friends / neighbors, what fraction of "triangles" are there?
		- graphlets: small subgraphs that describe structure around given node of interest
			- counts number of "different subgraphs" touched by a certain node
			- gives a **graphlet degree vector (GDV)**
				- provides means to summarize graph's local topology at the node
				- technically: count vector of graphlets rooted at the given node
					- look for slide titled "Node Features: Graphlets" in [[Lecture 2 - Traditional Methods for Machine Learning in Graphs.pdf|lecture slides]]
				- practically often only do graphlets up to size $n$ (they quickly explode)
			- rooted, connected, induced, non-isomorphic subgraphs
				- rooted: distinguishing the positions (taking one node as the "root" and distinguishing, say, place in the chain or position in center/edge of structure)
- more terminology
	- **induced subgraph**: graph taken from another graph formed with subset of vectors and *all* edges connecting verticies in subset
	- **graph isomorphism**: when graphs "capture the exact same connectivity pattern"
		- same # of nodes connected in same ways

### Features
- importance-based features (for predicting influential nodes, e.g. "celebrities")
	- node degree
	- different node centrality measures (eigenvector, betweenness, closeness)
		- models importance of neighboring nodes
- structure-based features (topological properties of local neighborhood, like "roles" played in a network)
	- node degree
	- clustering coefficient
	- graphlet count vector

## Link-Level Prediction
### Goal
- predict new links based on existing ones (*link prediction task*)
	- if network evolves (over time) or is incomplete (missing at random?)

### Methodology
- for pair of nodes $x,y$ compute score $c(x,y)$
- sort nodes by decreasing score
- predict top $n$ pairs as new links

### Features
- **distance-based features**: shortest-path distance
- **local neighborhood overlap**
	- *common neighbors*
	- *Jaccard's coefficient* (intersection / union)
	- *Adamic-Adar index* (summation over neighbors of 1 over log degree of the neighbors)
	- drawback: mostly 0 when nodes don't have common neighbors
- global neighborhood overlap
	- **Katz index:** count number of walks (paths, but cycles continue to revisit nodes) of all lengths between given node pair
		- use adjacency matrix!
		- $P^{(K)}_{uv}=$ # paths of length $K$ between $u$ and $v$
			- $P^{(K)}=A^K$ (use *powers* of adjacency matrices)
			- $P^{(n)}_{uv}=\sum_i A_{ui}*P_{iv}^{(n-1)}$
		- the Katz *similarity* or *score* is sum over all path lengths w/ exponential decaying factor
			- $S_{v_1, v_2}=\sum_{l=1}^\infty \beta^l A_{v_1 v_2}^l; 0<\beta<1$
				- close form solution exists to solve this

## Graph-Level Prediction
### Goal
Features that characterize structure of entire graph
- use notion of a **kernel**

### Kernels
- Kernel $K(G, G')\in\mathbb{R}$ measures similarity btwn data (basically a similarity metric)
- Kernel matrix $\mathbf{K}=(K(G,G'))_{G,G'}$ must always be *positive semidefinite* (has positive eigenvalues)
- Exists feature representation $\phi(\cdot)$ s.t. $K(G,G')=\phi(G)^T\phi(G')$
	- Allows us to calculate kernel as dot product of two featurizations of these two graphs
- Once kernel is defined, can use off-the-shelf ML models like **kernel SVM**

#### Designing Kernels
- Key idea: **bag-of-words** for a graph
	- Naive idea: nodes are "words"
	- Better idea: bag of *node degrees*
#### Graphlet Kernel
- "bag-of-graphlets" implementation
	- how many instances of given graphlet appear in my graph?
	- problem: larger graphs will have skewed values for dot product between them
		- normalize each feature vector by sum
		- $\mathbf{h}_G = \mathbf{f}_G / \text{Sum}(\mathbf{f}_G)\longrightarrow K(G,G') = \mathbf{h}_G^T\mathbf{h}_{G'}$
- Slightly different notion of graphlets than in [[#Features|node feature]] section
	- nodes in graphlets need not be connected
	- not rooted
#### Weisfeiler-Lehman (WL) Kernel
Not covered this lecture