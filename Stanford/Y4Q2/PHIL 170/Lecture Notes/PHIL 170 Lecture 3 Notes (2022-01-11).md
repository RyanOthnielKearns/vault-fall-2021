#Stanford #Stanford-Winter-2022 #philosophy #PHIL170 #lecture-notes #ethics #utilitarianism #John-Rawls #JCC-Smart #Bernard-Williams
___
- adding Williams to the debate about "Team Rawls" vs. "Team Smart"
- kinds of concerns that Williams raises: integrity, feeling, etc. ways in which the utilitarian position influences us to be alienated from our own moral personalities
	- is he implicating the position advocated by Rawls?
- Rawls wants to weaken the link: states of affairs *are* better when they have more pleasure in them, and *yet* still for the individual, better coordinate actions with social system, defer decision making to the rules of the practice rather than promote utilitarianism "directly"

# Bernard Williams, "A Critique of Utilitarianism"
## Review: Smart on Promises, Vows, Laws, Property
from [[202201060952 PHIL 170 Lecture 2 Notes (2022-01-06)]]
- if you accept extreme version of the utilitarian doctrine --> at any point, if a person has a decision to make about what to do, *they have the authority* to consider which action available to them would produce the most happiness
	- not only permissible, but the correct rational call to deliberate --> to think otherwise is to make some kind of rational error
	- at most, should be cautious about biases or the propensity to make errors in the calculation
		- deferring to the *epistemic* authority of others might be wise --> these are "rules of thumb"
			- the only deference in a "Smartian" society would be a kind of epistemic deference
	- what kind of society is possible under complete adoption of extreme utilitarianism?
		- nobody could intelligently could make promises, respect property rights, pass laws, etc.
		- would people need to make these kinds of committments?

Rawls trying to dunk on Smart: "if one applies this view to rules, one is interpreting them as maxims, as "rules of thumb"; and it is doubtful that anything to which the summary conception did apply would be called a rule. Arguing as if one regarded rules in this way is a mistake one makes while doing philosophy."
- Smart: things like marriage vows don't *actually* bind in a nonarbitrary way -- they deserve to be weakened if people are willing to reevaluate them on utilitarian grounds
	- why should this be a *reason* not to leave your own marriage if you're an extreme utilitarian?

## Williams' Critique
*main thought*: utilitarianism cannot capture the proper moral place of *integrity*
- **integrity**: consistency in thought and action over time? about wholeness or harmony as a person
	- forming a coherent and stable "moral self" -- a locus of "moral personality" that constitutes one's center
	- a sense of deep responsibility to one's actions
	- e.g. putting principle ahead of what one immediately wants
	- utilitiarianism makes it hard to see how a person might maintain integrity -- and why it should matter if anyone does maintain it
		- if what actually matters is utility -- why are we getting hung up on integrity, which might just not even advocate the best moral actions according to utility?

### Examples
#### Caveats
- it's not straightforward how Williams' examples relate to "conventional" arguments against utilitarianism from [[202201060952 PHIL 170 Lecture 2 Notes (2022-01-06)|last time]], e.g. punishment and promising
	- not also directly about pointing out how utilitarian reaches the wrong verdict (the utilitarian verdict in Jim's case might get it right, actually)
	- rather, what is morally important to *think* / *feel* when we figure out what we should do (and how utilitarianism doesn't provide us with the proper thinking / feeling, and that's something we want from moral philosophical accounts)
- these arguments are clearly addressed to those who are *not yet* utilitarians (an external critique)
	- "If you're already bought into Smart's stuff, you're a lost cause to me anyway..."
	- "You're thinking about signing onto a new religion / club? I'm going to talk you out of it"
		- "Don't fail to notice the _dramatic costs_ that come with accepting this viewpoint, which is going to influence how you see and act in the world" -- it's much more radical than that! Even if you do end up going his way, acknowledge that

#### Negative Responsibility
- distinguish btwn **acts** and **omissions**
	- according to utilitarianism, a person is equally responsible for the harms we cause both through our actions *and* our omissions (what harm we fail to prevent through inaction)
	- the more important point: **other agents**
		- a person is just as responsible for the consequences of her actions / omissions, even when the consequences result from the actions of *another agent*
		- the Pedro example: seems to make a *big* difference
		- what the utilitarian is telling you to do *denies* you the thought that "Pedro is responsible for Pedro's shooting of people. *I'm* not responsible for what Pedro does." ("At least, I'm not responsible for that in the same way I'm responsible for my actions")
		- It *is* true that regardless, you do have to choose whether or not you intervene and change the situation
			- What ultimately matters to the utilitarian: what *I can do* can have a positive influence on the overall utility *regardless* of what other agents do
- Williams is normally quite hostile to Kantian ethical thinking, but agrees with Kant here: the position you're being put in in Pedro's case is *not* a position in which you have a choice. That's absurd. You're being coerced
- Sense of responsibility that Williams is after: less "is to blame for", more "one's being responsible *for* one's child"
	- Even though the "is to blame for" idea is a popular and accepted one within moral philosophy
	- "Falls within the ambit of / is within the purview of one's decisionmaking"
	- The utilitarian is inviting you to think that it's within *your* ambit to consider the consequences of someone else's actions (the causal upshots of what you choose to do)

#### Feelings
Jim and George are likely to *feel* various things: distress about their situations / choices, guilt or regret after the fact, etc.
- these feelings are apt to characterize one's decision-making in these situations
- what is the status of those feelings? what *would* their status be on the utilitarian theory?
	- one option: as unpleasant feelings, they "count" against the actions that cause them
		- but agent's guilt will pale in comparison to the other considerations of utility
		- an evil person's pleasure in doing evil things counts the same as a good person's pleasure in doing good things...?
	- assuming that the action required is clear on the utility account, the feelings appear unwarranted / irrational -- what's the point of feeling guilt after making the proper choice w.r.t. utility?
		- but some strictly irrational feelings are still *useful* from a moral pt of view
		- the utilitarian might conclude that we're better off without moral feelings *at all* -- think in a cold and calculating way with no emotional registration -- this feels alien
	- puzzling and alienating to relate to one's own feelings in this way... the relationship is more intimate than utilitarianism allows
		- what a person feels is wrong, regrettable, shameful, etc. -- essential expressions of that person's moral judgements / attitudes and so a part of the moral identity
- guilt as blame directed at oneself