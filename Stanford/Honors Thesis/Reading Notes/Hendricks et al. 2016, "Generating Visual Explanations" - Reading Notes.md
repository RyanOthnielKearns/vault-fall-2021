# Hendricks et al. 2016, "Generating Visual Explanations"
## #reading-notes 
___
In this paper, Hendricks et al. design an AI system that can output natural language explanations for image classification decisions. Their design philosophy is guided by the idea that explanations should be class discriminative (differentiate the prediction decision compared to other candidate classes) and image relevant (accurately describe the features of the given image). Technically, Hendricks et al. design their model to minimize two loss functions, one called Discriminative Loss and one called Relevance Loss. Discriminative Loss utilizes techniques from RL and introduces an "expected discriminator reward," which is the probability of the ground truth category given the generated description. Relevance Loss is defined using the probability of predicting the ground truth word in the LSTM that generates word sequences.

Hendricks et al. make a point to differentiate introspection explanation, which examines properties of the system and how they influenced the classification decision, and justification decision, which points to features of the input that indicate why the classification was made. The authors believe that justification decisions are valuable because they are interpretable by people without AI expertise. They also differentiate explanation from description, which has high relevance to the input image but low discriminating force, and definition, which discriminates the class but may not be relevant to the image.

In the Results section, Hendricks et al. find that their "Explanation" system with the 2 loss functions performs better at both image and class relevance when it comes to outputting natural language explanations of classifications. Also, human experts found the "Explanation" model more convincing. Anecdotally, they find their model better at picking out rare and differentiating image features than ablation models, and also better at including class features even without access to the true class label (at test time).