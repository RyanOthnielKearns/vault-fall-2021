# [[Coeckelbergh 2012, “Can we trust robots?” (ANNOTATED).pdf|Coeckelbergh 2012, "Can we trust robots?"]]
## #reading-notes 
Tags #trust #robots 
Date: 2020-11-14
___
This paper has two basic contributions.

First, the author distinguishes two views on trust to frame the question. In the first, called the *contractarian-individualist* approach, individuals make rational choices to trust based on their social situation and expectations. In the latter, called the *phenomenological-social* approach, the community or social scenario is prior to the individual, so trust is not as much decided as it is latent in specific social interactions. In other words, trust is *created* in the former view, *presupposed* in the latter. The author supports the latter view, which seems to be the less popular one on the topic of trust in technology generally.

The second contribution concerns the question of whether "trust" is something appropriate to ascribe to robots. Theories of trust are predominantly interpersonal theories (see even the [[McLeod 2015, "Trust" - Reading Notes|SEP article on trust]]), except when we talk about trusting artefacts, where trust is an expectation an instrument will function. In this latter case, we talk about "trust as reliance" (54). Robots are a special case, in that you can debate whether they're better understood as "quasi-others" (57) and thus interpretable under the human-human theories of trust. Being a "quasi-other" is dependent on the robot's ability to be social, use language related to trust, and operate as a free agent. In the event that robots don't fullfil these criteria, Coeckelbergh suggests we resort to a "functionalist, performance criterion" (58): can we trust the robot to do what it's expected to do / what we've intended it to do?