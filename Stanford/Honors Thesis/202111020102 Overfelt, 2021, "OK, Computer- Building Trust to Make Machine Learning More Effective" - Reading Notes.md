https://www.gsb.stanford.edu/insights/ok-computer-building-trust-make-machine-learning-more-effective

- people worth talking to about this?
	- Maggie Overfelt (author)
	- [https://www.gsb.stanford.edu/faculty-research/faculty/sara-singer](Sara Singer), professor of organizational behavior at Stanford
- this seems like an example where the users of the system trust the *developers* primarily
	- and then the system by extension? or no
	- is there a sense in which trust *transferred* from the developers to the system? what the system anthropomorphized to any extent during the trusting process?
		- or is it okay to have an instance of "trust in machine learning" where minimal trust is put into the machine learning algorithms themselves, but rather just the developers of and stakeholders in the technology?