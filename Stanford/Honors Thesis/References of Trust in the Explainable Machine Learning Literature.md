[[Doshi-Velez et al., "The Role of Explanation in Algorithmic Trust".pdf]]:
> When it comes to human decision-makers, we often want an explanation when someone makes a decision we do not understand or believe to be suboptimal. For example, was the conclusion accidental or intentional? Was it caused by incorrect information or faulty reasoning? **The answers to these questions permit us to weigh our trust in the decision-maker** and to assign blame in case of a dispute. (1)


> Thus, the question of algorithmic trustworthiness is more complicated than a binary choice between systems that generate explanation or systems that do not. (2)