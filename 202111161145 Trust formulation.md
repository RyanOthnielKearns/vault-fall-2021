$T(a,b,x,C)$ iff:
1. $a$ expects that $b$ will $x$ with a certain *weighted normative expectation* (one poised for betrayal) (the **investment** condition)
	1. Contrapositively: $a$ does *not* *know* that $b$ will *not* $x$ (maybe this is its own condition?)
2. $a$ is disposed to act as though $b$ will $x$ (the **employment** condition)
3. $a$ believes each $c\in C$ to hold for $b$

So trust is a sort of "employment with investment" that's responsive to one's beliefs
- this doesn't require that the trustor is in any way left vulnerable to the trustee (though this will often be the case)
	- vulnerability is sort of codified by *what's absent* from $C$ (still working on formalizing this!)

Importantly leaving out:
- any notion that $a$'s vulnerability to $b$ $x$ing is in any way essential to trust
	- e.g., $T(a, b, x, C)$ with $\langle a \text{ knows that } b\text{ will } x\rangle\in C$ is possible
- that $a$ expects or *believes* that $b$ will $x$ (therapeutic trust, also vulnerable trust)

Maybe this is about the particular sub-problem of *trusting algorithms*?
- this is more specific than trust in general, and restricts us to only *functional* cases where we have a given input and produce an output -- we can either trust the process that produces the output or not